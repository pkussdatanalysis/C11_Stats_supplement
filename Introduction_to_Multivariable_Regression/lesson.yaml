- Class: meta
  Course: Regression_Models
  Lesson: Introduction_to_Multivariable_Regression
  Author: your name goes here
  Type: Standard
  Organization: your organization's name goes here
  Version: 2.4.3

- Class: text
  Output: 在本课中，我们将说明多变量的回归等于一系列单变量回归，通过在一个变量中使用回归，我们将展示如何消除任何可选择的回归元，
    从而N个变量的回归减少为N-1个变量的回归。因此，如果我们知道如何在1个变量中做回归，那么我们可以在2中进行回归。
    一旦我们知道如何在2个变量中做回归，我们可以在3个变量中进行回归，等等，我们首先从galton数据开始，并学习一下通过减去均值的方式来消除截距

- Class: text
  Output: 当我们在一个变量中进行回归时，如lm（child~parent，galton），我们得到两个系数，一个斜率和一个截距，
    截距实际上是一个具有固定值1的特殊变量的特殊回归系数，在每个样本中，函数lm默认包含这个回归因子。

- Class: cmd_question
  Output: 我们将替换全部为1回归元来，这个回归元必须和样本数相同（928）。创建这样一个对象并命名它为ones，
    使用ones<- rep(1, nrow(galton))，或者一些等同的表达
  CorrectAnswer: ones <- rep(1, nrow(galton))
  AnswerTests: calculates_same_value('ones <- rep(1, nrow(galton))');expr_creates_var('ones')
  Hint: 在R提示符处输入ones<- rep（1，nrow（galton））是形成全部值为1的向量的简单方法，其具有与galton数据集完全一样多的样本

- Class: cmd_question
  Output: galton数据已经被加载，默认的截距可以通过在公式中使用-1来排除。使用lm(child~ones + parent -1，galton)建立一个回归，
    使用我们的具有ones回归元来代替默认的回归元，因为我们希望打印结果，所以不要把它分配给一个变量
  CorrectAnswer: lm(child~ones + parent - 1,galton)
  AnswerTests: creates_lm_model('lm(child ~ ones + parent - 1, galton)');!expr_is_a("<-")
  Hint: 在R提示符处输入lm(child~ones + parent - 1,galton)，不要将结果赋给变量。

- Class: cmd_question
  Output: 1的系数是23.9415，现在使用默认的lm（child~parent，galton）来显示截距的值相同，这次不要用-1来抑制截距
  CorrectAnswer: lm(child ~ parent, galton)
  AnswerTests: creates_lm_model('lm(child ~ parent, galton)');!expr_is_a("<-")
  Hint: 在R提示符处输入lm（child~parent，galton）是最简单的事情，不要把结果赋给变量

- Class: mult_question  
  Output: 由lm（child~parent，galton）给出的一个变量的回归实际上涉及两个回归因子，变量parent和一个所有的值都是1的一个回归元
  AnswerChoices: True;False
  CorrectAnswer: True
  AnswerTests: omnitest(correctVal= 'True')
  Hint: 由于它产生两个系数，它必须包含两个回归元，一个是一个名为"parent"的变量，另一个是常数,1

- Class: figure
  Output: 由lm（child~parent，galton）给出的回归线经过了x = mean（parent），y = mean（child）的点，
    如果从每一个变量减去平均值，回归线都通过原点，x = 0，y = 0，因此它的截距为零.
    通过所有的变量都减去均值，我们消除了两个回归因子中的一个，常数，只剩下一个变量parent。剩余的回归系数是斜率
  Figure: eliminates_intercept.R
  FigureType: new

- Class: text
  Output: 减去均值消除截距的方法是一种通用技术的一个特例，有时也称为高斯消除法。在这里应用的通用技术是选择一个回归元，
    并用所有其他变量在这个单变量下产生的回归残差替换所有其他变量

- Class: mult_question  
  Output: 如所声称的那样，假设减去一个变量的均值是一个用残差代替变量的特殊情况，在这种特殊情况下，它将是对什么的回归的残差？
  AnswerChoices: The constant, 1;The variable itself;The outcome
  CorrectAnswer: The constant, 1
  AnswerTests: omnitest(correctVal= 'The constant, 1')
  Hint: 残差是变量与其预测值之间的差异，例如，如果child-mean(child) 是一个残差，则mean(child)必须是其预测值，
    但mean(child)是一个常数所以回归元是一个常数

- Class: cmd_question
  Output: 一个变量的平均值是它在常数1下的回归系数，因此，减去平均值就等于用常量1下的回归的残差代替一个变量。在R公式中，
    常数回归可以是用右边的1表示，因此，表达式lm（child~1，galton）求孩子身高在常量1下的回归。在galton数据中，
    一个孩子的平均身高为68.09英寸。 lm（child~1，galton）将结果系数（截距）与平均高度68.09进行比较。因为我们希望打印结果，
    所以不要给它命名
  CorrectAnswer: lm(child ~ 1, galton)
  AnswerTests: creates_lm_model('lm(child ~ 1, galton)');!expr_is_a('<-')
  Hint: 在R提示符处输入lm（child~1，galton），不要使用赋值运算符<- 。

- Class: mult_question  
  Output: 变量的平均值等于它对常数1的回归系数
  AnswerChoices: True;False
  CorrectAnswer: True
  AnswerTests: omnitest(correctVal= 'True')
  Hint: 平均数是使自身和变量之间的平方差之和最小的数字

- Class: cmd_question
  Output: 为了说明一般情况，我们将使用datasets包中的trees，这个想法是通过测量树木的高度和周长来预测树木可能产生的木材量，
    为了避免把截距当作一种特殊情况，我们在数据上增加了一个全是1的列，请花一点时间用View(trees)或者head(trees)来检查数据。
  CorrectAnswer: head(trees)
  AnswerTests: ANY_of_exprs('View(trees)', 'head(trees)', 'trees', 'print(trees)')
  Hint: 在R提示符处输入head（trees）或View（trees）

- Class: text
  Output: 一个相关的代码文件已经被复制到你的工作目录中，并且加载到了工作空间了，elimination.R应该出现在你的编辑器中，如果没有，请手动打开它

- Class: mult_question  
  Output: 一般的技术是选择一个预测变量，用所有其他的变量在选择的预测变量下的回归残差来代替他们，eliminate.R中的函数regressOneOnOne在执行这个过程的第一步，
    给定一个预测变量的名字和另外一个变量是其他变量中的一个，代码中叫做regressOneOnOne函数中other，当对预测变量回归时，它返回其他变量的残差，在它的第一行标记为A的点上，
    它创建了一个公式，假设预测变量是'Girth'，另一个变量是'Volume'。创建一个什么样的公式？
  AnswerChoices: Volume ~ Girth - 1;Girth ~ Volume - 1;Volume ~ Girth
  CorrectAnswer: Volume ~ Girth - 1
  AnswerTests: omnitest(correctVal= 'Volume ~ Girth - 1')
  Hint: 这个公式将表示在单预测变量Girth下Volume的回归,，使用公约-1来抑制默认截距，以达到目的。

- Class: text
  Output: 除了给定的预测变量之外，函数eliminate，对所有的变量都应用regressOneOnOne，并且收集数据框中的残差。我们首先显示，
    当我们从数据中消除一个回归因子时，剩余的回归将产生它们正确的系数（当然，消除的回归因子的系数将会丢失，但更多的是在后面）

- Class: cmd_question
  Output: 作为参考，基于所有三个回归因子：Girth，Height和Constant，创建一个名为fit的模型，并将结果赋值给一个名为fit的变量。
    使用一个表达式，例如fit <- lm（Volume~Girth + Height + Constant - 1，trees）。不要忘记-1，并确保命名适合以后使用的模型。
  CorrectAnswer: fit <- lm(Volume ~ . - 1, trees)
  AnswerTests: creates_lm_model('fit <- lm(Volume ~ . - 1, trees)')
  Hint: 在R提示符处输入一个表达式，例如fit <-lm（Volume~Girth + Height + Constant - 1，trees）或fit <-lm（Volume~.-1，trees）。

- Class: cmd_question
  Output: 现在让我们从数据集中取出Girth，调用简化的数据集trees2来表示它只有2个回归因子，使用表达式trees2 <- eliminate（"Girth "，trees）
  CorrectAnswer: 'trees2 <- eliminate("Girth", trees)'
  AnswerTests: ANY_of_exprs('trees2 <- eliminate("Girth", trees)', "trees2 <- eliminate('Girth', trees)");expr_creates_var("trees2")
  Hint: 在R提示符下输入trees2 <- eliminate("Girth", trees)。

- Class: cmd_question
  Output: 使用head（trees2）或View（trees2）来检查缩减的数据集
  CorrectAnswer: head(trees2)
  AnswerTests: ANY_of_exprs('head(trees2)', 'View(trees2)', 'trees2')
  Hint: 在R提示符处输入head（trees2）或View（trees2）。
  
- Class: mult_question  
  Output: 为什么在tree2中，恒定列不是恒定的？
  AnswerChoices: "The constant, 1, has been replaced by its residual when regressed against Girth.;There must be some mistake;Computational precision was insufficient."
  CorrectAnswer: The constant, 1, has been replaced by its residual when regressed against Girth.
  AnswerTests: omnitest(correctVal= 'The constant, 1, has been replaced by its residual when regressed against Girth.')
  Hint: Volume, Height, 和Constant每一列已经被在 Girth下的回归残差所取代，因为周长不是常数，lm(Constant ~ Girth -1, trees)的残差不会是恒定的“。

- Class: cmd_question
  Output: 现在使用简化的数据集创建一个名为fit2的模型，使用一个表达式，比如fit2 <- lm（Volume~Height + Constant -1，trees2），
    不要忘记在公式中使用-1。
  CorrectAnswer: fit2 <- lm(Volume ~ . - 1, trees2)
  AnswerTests: creates_lm_model('fit2 <- lm(Volume ~ . - 1, trees2)')
  Hint: 输入一个表达式，例如fit2 <-lm（Volume~Height + Constant -1，trees2）或fit2 <-m（Volume~.-1，trees2）。
    不要忘记在公式中使用-1，并命名模型fit2

- Class: cmd_question
  Output: 使用表达式lapply（list（fit，fit2），coef）打印fit和fit2的系数作为比较
  CorrectAnswer: lapply(list(fit, fit2), coef)
  AnswerTests: ANY_of_exprs('lapply(list(fit, fit2), coef)', 'lapply(list(fit2, fit), coef)')
  Hint: 在R提示符处输入lapply（list（fit，fit2），coef）。

- Class: text
  Output: 当然，消除的变量的系数是丢失的，一种方法是回到原始数据树上，消除一个不同的回归因子，比如Height，然后再做两个变量回归，
    如上我们已经展示了如何将3个变量的回归减少到2个回归，我们可以进一步消除另一个变量，减少2个变量的回归在1个变量回归“。

- Class: figure
  Output: 这是最后一步，我们使用eliminate("Height", trees2)来减少数据到结果，Volume和Constants回归因子。在上面的命令中，
    我们已经计算过Volume和Constants回归，并打印了系数结果。正如你所看到的，Constant的系数与之前的值是一致的。
  Figure: trees3.R
  FigureType: new

- Class: mult_question  
  Output: 假设我们得到了一个包含结果和N个回归因子的多变量回归问题，其中N> 1。只使用单变量回归，问题如何仅仅减少到N-1回归的问题？
  AnswerChoices: "Pick any regressor and replace the outcome and all other regressors by their residuals against the chosen one.;Subtract the mean from the outcome and each regressor."
  CorrectAnswer: "Pick any regressor and replace the outcome and all other regressors by their residuals against the chosen one."
  AnswerTests: omnitest(correctVal= 'Pick any regressor and replace the outcome and all other regressors by their residuals against the chosen one.')
  Hint: 减去平均值是一个特殊情况，只适用于常数回归因子，并不是每一个问题都会涉及一个常量的回归因子
  
- Class: text
  Output: 我们已经说明了在许多变量中的回归在一个回归中是一系列的回归，像lm这样的函数所使用的实际算法效率更高，
    但是在计算上等同于我们所做的。也就是说，算法使用等价但更有效率和抽象地结合起来。  
    
- Class: mult_question
  Output: 确定将这次练习的结果提交吗?
  CorrectAnswer: NULL
  AnswerChoices: Yes;No
  AnswerTests: post_on_demand()
  Hint: ""

